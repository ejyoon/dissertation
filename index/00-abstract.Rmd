Children's rapid language development is one of the more remarkable features of human cognition. How do they learn so much despite ambiguous input and limited processing capabilities? Social learning theories argue for the importance of acquiring language from more knowledgeable adults who constrain the learning task. Statistical learning accounts emphasize the role of pattern detection and structure in children's language environment. Finally, active learning explanations focus on children's skill in seeking information to support their own learning. This thesis presents an integrative framework for unifying key ideas from these accounts, followed by a diverse set of case studies of eye movements during language processing and word learning. The empirical work highlights how children's gaze patterns can flexibly adjust to the demands of very different learning environments.

Chapter 1 uses the formalization of Optimal Experiment Design (OED) to provide an integrative account of information seeking within social contexts. Chapter 2 presents the first case study: children's eye movements during real-time processing of American Sign Language (ASL) where objects and language compete for visual attention. Chapter 3 provides a direct comparison of eye movements during signed and spoken language comprehension, proposing an information-seeking explanation of why ASL-learners are slower to shift gaze away from their social partners and to named objects. Chapters 4 and 5 generalize the information seeking explanation to the domain of novel word learning. Chapter 4 presents a series of large-scale word learning experiments, showing that the presence of social cues can change how adults distribute attention and memory during statistical learning. Finally, Chapter 5 presents an eye tracking study measuring how children's decisions to gather visual information about social partners vs. objects changes as a function of their knowledge of word-object links.
