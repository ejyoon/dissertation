```{r, include=FALSE}
knitr::opts_chunk$set(echo = F, cache = T, warning=F, message=F, 
                      fig.width=4, fig.asp = 0.618, out.width = "90%", 
                      fig.align = 'center', fig.pos = '!t')

fig_path_intro <- "index/chapter_child_rmds/Intro/figs"
source(here::here("index/disseration_helpers.R"))
```

Early language acquisition seems simple. An adult produces a word referring to something in the surrounding context (e.g., "look at the ball") and the child connects what they hear with the round object that they see in front of them. This characterization of language learning via association belies the complexity of the processing and acquisition challenges that children face. Consider that even to process the meaning of concrete nouns, children have to extract the correct units from a continuous stream of linguistic information and link it to another continuous stream of visual information. The word-to-meaning mapping task becomes even more complex when we consider that the co-occurring context does not often disambiguate a speaker's intended meaning. This point was made famous by W.V. Quineâ€™s example of a field linguist trying to select the target meaning of a new word ("gavagai") from the set of possible meanings consistent with the event of a rabbit running (e.g., "white," "rabbit," "dinner," etc.) [@quine19600]. Remarkably, children's word learning proceeds rapidly, with estimates of adult vocabularies ranging from 50,000 to 100,000 distinct lexical concepts [@bloom2002children].

The number of word meanings that children acquire is not the only impressive feature of their lexical development. As children accumulate word knowledge, they also gain the capacity to access conceptual representations linked with words quite rapidly. Consider that children can understand language even though adults speak at a rate of three words per second, and empirical work shows that even young children will shift their visual attention to a familiar object within hundreds of milliseconds upon hearing its name [@fernald2006picking]. The speed of lexical access becomes even more apparent when compared with the slower retrieval of other learned, arbitrary facts (e.g., phone numbers).

These phenomena have made children's language comprehension and word learning fundamental topics of research in cognitive science. How is it that nearly all children growing up under normal circumstances acquire language despite noisy input? What mechanisms could account for the robustness and flexibility of language learning?  

Social-pragmatic accounts point out that the child does not have to re-invent language on their own. Instead, children are typically surrounded by parents, other knowledgeable adults, or older peers -- all of whom know the target language and can facilitate their learning [@bloom2002children; @clark2009first; @hollich2000breaking]. Statistical learning theories propose that children possess powerful pattern detection skills that can learn the consistent structure in their input and reduce ambiguity in the learning task [@yu2007rapid; @siskind1996computational; @roy2002learning]. Recent theories highlight the role of children as active learners, who can influence the content, pacing, and sequence of their experience via actions such as question asking or choosing where to allocate visual attention [@gopnik1999scientist; @schulz2012origins]. A common thread across the social, statistical, and active accounts is that children have access to information that can *constrain* the inferences about reference during language processing, thus reducing the problem of indeterminacy in the input.

Empirical work in each of these traditions has typically proceeded in parallel, isolating the effects of each process on various domains of cognitive development. In real-world environments, however, children can integrate social and statistical information while also actively constructing their own learning experiences. To better understand this complexity, it becomes important to develop integrative accounts that can explain how different sources of information might mutually influence one another during learning. But how do we integrate ideas from diverse theoretical accounts that may lack clear definitions and formal theory? In this thesis, I argue that answering this question is important because children learn language from interactions with other people, which provides them with an opportunity to integrate social information with their prior knowledge to select actions that support their language learning.

Figure 1 shows a schematic overview of the contents of this dissertation. Chapter 1 presents the details of an integrative account of how social contexts shape children's active learning. I use the computational framework of Optimal Experiment Design [@emery1998optimal; @lindley1956measure] as a conceptual tool to bring social learning processes into contact with the underlying decision making that supports children's information seeking. The key insight is that learning in the presence of other people plays a direct role in determining the *usefulness* of different actions. Using this framework allows us to ask how social and statistical information might selectively affect the different underlying components of children's information selection during lexical comprehension and word learning.

```{r schematic-overview, fig.cap = "The upper panel shows a schematic overview of the components of an integrative framework of information seeking during language processing within a social context. The lower panels show the different case studies and pieces of the general framework that correspond to each chapter of the dissertation.", fig.scap="Schematic overview of the dissertation content."}

include_graphics(path = here::here(fig_path_intro, "schematic_overview.jpeg"))
```


Chapters 2-5 describe a diverse set of case studies of children and adult's eye movements during real-time familiar language comprehension and novel word learning. The empirical work focuses on eye movements as one instantiation of an active learning behavior that is particularly relevant for early lexical development. That is, we can characterize decisions about visual fixation as a type of question-asking where perceivers deploy their gaze to reduce uncertainty about the world and to maximize their expected future rewards concerning some goal [@hayhoe2005eye]. Moreover, eye movements are a behavior that children can control relatively early in development and map well on to the ecological task of interest: linking linguistic and visual information about concrete objects. Overall, the goal of the empirical work is to ask how children's real-time visual information selection adapts to the information available across a wide range of processing contexts.
