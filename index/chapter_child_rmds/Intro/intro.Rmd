```{r, include=FALSE}
knitr::opts_chunk$set(echo = F, cache = T, warning=F, message=F, 
                      fig.width=4, fig.asp = 0.618, out.width = "90%", 
                      fig.align = 'center', fig.pos = '!t')

fig_path_intro <- "index/chapter_child_rmds/Intro/figs"
source(here::here("index/disseration_helpers.R"))
```

Early language acquisition seems simple. An adult produces a word about something in the surrounding context (e.g., "look at the ball") and the child connects what they hear with the round object that they see in front of them. This characterization of language learning via association belies the complexity of the processing and acquisition challenges that children face. Consider that learning the meaning of concrete nouns, children have to extract the correct units from a continuous stream of linguistic information and map them on another continuous stream of visual information. The word-to-meaning mapping task becomes even more complex when we consider that the co-occurring context does not often disambiguate a speaker's intended meaning. This point was made famous by W.V. Quineâ€™s example of a field linguist trying to select the target meaning of a new word ("gavagai") from the set of possible meanings consistent with the event of a rabbit running (e.g., "white," "rabbit," "dinner," etc.) [@quine19600]. Remarkably, children's word learning proceeds rapidly, with estimates of adult vocabularies ranging from 50,000 to 100,000 distinct lexical concepts [@bloom2002children].

The number of word meanings children will acquire is not the only impressive feature of their lexical development. As children accumulate word knowledge, they also gain the ability to access the conceptual representation linked with a word quite rapidly. Children can understand language even though adults speak at a rate of three words per second. And empirical work shows that both adults and young children shift their visual attention to a familiar object in the scene within hundreds of milliseconds upon hearing its name [@spivey2002eye; @allopenna1998tracking; @tanenhaus1995integration]. The speed of lexical access becomes even more impressive when compared with the slower retrieval of other learned, arbitrary facts (e.g., phone numbers) [@pinker2003language]. 

Together, these feaatures have made children's language comprehension and word learning fundamental topics of research in cognitive science. How is it that nearly all children growing up under normal circumstances acquire language despite noisy input? What learning mechanisms could account for the robustness and flexibility of language development?  

Social learning accounts point out that the child does not have to re-invent language on their own. Instead, children are typically surrounded by parents, other knowledgeable adults, or older peers -- all of whom know the target language and want to facilitate their learning [@bloom2002children; @clark2009first; @hollich2000breaking]. Statistical learning theories propose that children possess powerful pattern detection skills that can learn the consistent structure in their input and reduce ambiguity in the learning task [@yu2007rapid; @siskind1996computational; @roy2002learning]. More recent theories highlight the role child as an active learner, controlling aspects of their learning via the selection of behaviors -- for example, asking questions or choosing where to allocate visual attention -- that change the content, pacing, and sequence of their learning experiences [@gopnik1999scientist; @schulz2012origins]. A common thread across these three accounts -- social, statistical, and active -- is that children have access to information that *constrains* their inferences about new word meanings, thus reducing the problem of indeterminacy. 

Empirical work in each of these traditions has often proceeded in parallel, but, in real-world learning, these mechanisms do not operate in isolation. Thus, it becomes important to develop integrative accounts that try to explain how different sources of information might mutually influence one another during language development. But how do we integrate ideas from these proposals that often lack clear definitions and formal theory that generate testable predictions? In this thesis, I argue that answering this question is important because children learn language from interactions with other people, which provides the opportunity to integrate social information with their prior knowledge to select actions that support their language learning.

Figure 1 shows a schematic overview of the contents of this dissertation. Chapter 1 presents the details of an integrative account of how social contexts shape children's active learning. I use the computational framework of Optimal Experiment Design [@emery1998optimal; @lindley1956measure] as a conceptual tool to bring social learning processes into contact with the underlying decision making that supports children's information seeking. The key insight is that learning in the presence of other people plays a direct role in determining the *usefulness* of different actions. Using this framework allows us to ask how social and statistical information might selectively affect the different underlying components of children's information selection during lexical comprehension and word learning.

```{r schematic-overview, fig.cap = "The upper panel shows a schematic overview of the components of an integrative framework of information seeking during language processing within a social context. The lower panels show the different case studies and pieces of the general model that correspond to each chapter of the dissertation.", fig.scap="Schematic overview of the dissertation content."}

include_graphics(path = here::here(fig_path_intro, "schematic_overview.jpeg"))
```

Chapters 2-5 describe a diverse set of case studies of children and adult's eye movements during real-time familiar language comprehension and novel word learning. The empirical work focuses on eye movements as one instantiation of an active learning behavior that is particularly relevant for early lexical development. That is, we can characterize decisions about visual fixation as a type of question-asking where perceivers deploy their gaze to reduce uncertainty about the world and to maximize their expected future rewards concerning some goal [@hayhoe2005eye]. Moreover, eye movements are behaviors that children can control relatively early in development and map well on to the ecological task of interest: linking linguistic and visual information about concrete objects perceived via the visual channel. Overall, the goal of the empirical work is to ask how children's real-time visual information selection adapts to the information available across a wide range of processing contexts.

