# Seeking visual information ^[Parts of this chapter were published as @macdonald2017info An information-seeking account of eye movements during spoken and signed language comprehension and as @macdonald2018noise Adults and preschoolers seek visual information to support language comprehension in noisy environments. Proceedings of the 39th and 40th Annual Meetings of the Cognitive Science Society.]

In this chapter, we present two studies of eye movements during real-time familiar language processing. Within our broader active-social framework, these studies explore whether children adapt their eye movements to query locations in response to the utility of that location for their goal of rapid language comprehension. Moreover, these studies investigate children's decisions to stop fixating on a social partner and seek a named referent, synthesizing threshold models of decision making, stopping rules, and language-driven visual attention. 

Real-time language comprehension involves linking the incoming linguistic signal to the visual world. Information that is gathered through visual fixations can facilitate the comprehension process. But do listeners flexibly select what visual information to gather? Here, we propose that children flexibly adapt their gaze to seek visual information from social partners to support language understanding. We present evidence for our explanation using two case studies of eye movements during real-time language processing: children learning spoken English vs. young ASL-learners and spoken English in noisy vs. clear auditory environments. Across both studies, we found that listeners adapted their gaze to fixate longer on a social partner when it was useful for language comprehension. Fixating longer on their social partner led to a higher proportion of gaze shifts landing on the named objects, and more language-driven, as opposed to random, shifts. These results suggest that children can adapt their information gathering thresholds to seek additional visual information from their social partners that support their real-time language comprehension.

```{r schematic-speed-fam, fig.cap="A schematic showing the components of the OED model captured by the case studies in Chapter 3.", fig.scap="Overview of Chapter 3."}
data_code_path_saf <- "index/chapter_child_rmds/SPEED-ACC-FAM"
include_graphics(path = here::here(data_code_path_saf, "figures/speed_familiar.jpeg"))
```

```{r child = 'chapter_child_rmds/SPEED-ACC-FAM/saf_chapter.Rmd'}
```
