---
title: "Polite language reflects competing informational and social goals"
author: 'Erica J. Yoon'
date: 'May 2019'
advisor: 'Michael C. Frank'
firstreader: 'Ellen M. Markman'
secondreader: 'Noah D. Goodman'
thirdreader: 'Hyowon Gweon'
department: 'Psychology'
institution: 'Stanford University'
knit: "bookdown::render_book"
site: bookdown::bookdown_site
output: 
  thesisdown::thesis_pdf: 
      latex_engine: xelatex
#  thesisdown::thesis_gitbook: default
#  thesisdown::thesis_word: default
#  thesisdown::thesis_epub: default
# If you are creating a PDF you'll need to write your preliminary content here or
# use code similar to line 20 for the files.  If you are producing in a different
# format than PDF, you can delete or ignore lines 20-31 in this YAML header.
abstract: |
  `r if(knitr:::is_latex_output()) paste(readLines("00-abstract.Rmd"), collapse = '\n  ')`
# If you'd rather include the preliminary content in files instead of inline
# like below, use a command like that for the abstract above.  Note that a tab is 
# needed on the line after the |.
acknowledgements: |
  This work is not my own, and rather it is work of many people without whom this entire journey would not have been possible. 
  
  First I would like to thank my advisor Mike Frank -- he is the most wise, thoughtful and caring adviser that I could have ever hoped to have. I’m so fortunate to have had a mentor with such patience and trust that he showed for me more than the trust I had for myself, and if I were to ever be a mentor to someone, I hope I show the same kind of trust to my mentee that Mike shared with me for the last six years.
  
  I also had the privilege of working with incredible committee members who are so wise, insightful and generous. Ellen Markman, Noah Goodman, and Hyo Gweon have inspired me and encouraged me for every little progress I made, for which I am grateful.
  
  I’ve also had the privilege of collaborating and being friends with wonderful people in Language and Cognition Lab and the Developmental area in the Psychology Department.

  

 
bibliography: bib/thesis.bib
# Download your specific bibliography database file and refer to it in the line above.
csl: csl/apa.csl
# Download your specific csl file and refer to it in the line above.
lot: true
lof: true
#space_between_paragraphs: true
# Delete the # at the beginning of the previous line if you'd like
# to have a blank new line between each paragraph
header-includes:
- \usepackage{array}
- \usepackage{float}
- \usepackage{tabularx}
- \usepackage{longtable}
- \usepackage{afterpage}
- \usepackage{threeparttable}
- \usepackage{pdflscape}
- \newcommand{\blandscape}{\begin{landscape}}
- \newcommand{\elandscape}{\end{landscape}}

---

<!--
Above is the YAML (YAML Ain't Markup Language) header that includes a lot of metadata used to produce the document.  Be careful with spacing in this header!

If you'd prefer to not include a Dedication, for example, simply delete lines 17 and 18 above or add a # before them to comment them out.  If you have other LaTeX packages you would like to include, delete the # before header-includes and list the packages after hyphens on new lines.

If you'd like to include a comment that won't be produced in your resulting file enclose it in a block like this.
-->

<!--
If you receive a duplicate label error after knitting, make sure to delete the index.Rmd file and then knit again.
-->

```{r include_packages, include = FALSE}
# This chunk ensures that the thesisdown package is
# installed and loaded. This thesisdown package includes
# the template files for the thesis.
if(!require(devtools))
  install.packages("devtools", repos = "http://cran.rstudio.com")
if(!require(thesisdown))
  devtools::install_github("ismayc/thesisdown")
library(thesisdown)
if(!require(here))
  install.packages("here")
library(here)
```

<!-- You'll need to include the order that you'd like Rmd files to appear in the _bookdown.yml file for
PDF files and also delete the # before rmd_files: there.  You'll want to not include 00(two-hyphens)prelim.Rmd
and 00-abstract.Rmd since they are handled in the YAML above differently for the PDF version.
-->

<!-- The {.unnumbered} option here means that the introduction will be "Chapter 0." You can also use {-} for no numbers
on chapters.
-->

# Introduction {-#intro}

```{r child = 'chapter_child_rmds/ch0_intro/intro.Rmd'}
```


<!--chapter:end:index.Rmd-->

# A goal-based account of polite language

\chaptermark{A goal-based account of polite language} 

```{r child = 'chapter_child_rmds/ch1_goal_account/goal_account.Rmd'}
```

<!--chapter:end:01-theory.Rmd-->

# Children understand social goals behind polite requests ^[This chapter is submitted and currently under review for the 41st Annual Meeting of the Cognitive Science Society, and is joint work with Michael C. Frank.]

\chaptermark{Children's understanding of polite requests} 

In this Chapter, I start to explore what children understand about polite speech. Looking at children's polite speech comprehension can help examine children's pragmatic understanding more generally, and can be informative for caregivers who want to teach children what it means to be polite. Even though children start to produce polite speech from early on, there is little known about whether they understand intentions behind polite language. In this Chapter, I show that by 3 years, English-speaking preschool children understand that it is more polite and nicer (and less rude and mean) to use politeness markers such as \"please\" when making requests, and by 4 years, they understand that the use of these politeness markers indicates that the speaker is more socially likeable and is more likely to gain compliance from their conversational partners. This work can help lay the foundation for future work on children's understanding of polite speech and pragmatic development more generally.

```{r child = 'chapter_child_rmds/ch2_polite_requests/polite_requests.Rmd'}
```


<!--chapter:end:02-child_rule.Rmd-->

# Children consider tradeoffs between informational and prosocial goals to evaluate speakers

\chaptermark{Children's understanding of goal tradeoffs} 

In the last Chapter, I reported on empirical evidence that children are sensitive to speakers' goals to be prosocial and kind.
In this Chapter I examine whether older children are capable of a more sophisticated reasoning about the tradeoff between speakers' prosocial and informational goals, using a case study of prosocial lies (versus blunt truths). 
We show that adults and 5- to 8-year-old children reason about goal tradeoffs based on context at hand, and understand that the same lie (e.g., "your cookie was tasty") should be judged differently depending on the speaker's goals, whether the speaker meant to be kind or simply misleading without any apparent reason. 

```{r child = 'chapter_child_rmds/ch3_polite_lies/polite_lies.Rmd'}
```

<!--chapter:end:03-child-inference.Rmd-->

# Adults consider tradeoffs between competing social goals to predict polite language use ^[This chapter is submitted and currently under review at *Open Mind*, and is joint work with Michael Henry Tessler, Noah D. Goodman and Michael C. Frank.]

\chaptermark{Modeling polite speech} 

Language is a remarkably efficient tool for transmitting information. Yet human speakers make statements that are inefficient, imprecise, or even contrary to their own beliefs, all in the service of being polite. What rational machinery underlies polite language use? 
In this Chapter, we present evidence that adults think of polite speech as emerging from competing communicative goals: to convey information, to be kind, and to present oneself in a good light. 
We formalized this goal tradeoff using a probabilistic model of utterance production, which predicts human utterance choices in socially-sensitive situations with high quantitative accuracy, and we show that our full model is superior to its variants with subsets of the three goals. 

```{r child = 'chapter_child_rmds/ch4_modeling_polite/modeling_polite.Rmd'}
```


<!--chapter:end:04-adult.Rmd-->

# Conclusion {-#conclusion}

In this dissertation, I proposed a framework to unify existing theories to understand polite language as reflecting a tradeoff between different goals that speakers may consider. 
Critically, language does not only reflect speakers' informational concerns to convey accurate information informatively, 
but also non-informational social concerns, such as following social norms and maintaining listeners' and speakers' own positive self-image (*face*).
In Chapter 1, I summarized previous approaches to polite language and argued that a goal-based framework can integrate different components that are important to explaining how polite speech emerges and is understood. 
Then I explained how existing empirical data with adults and children that can be explained through this goal-based framework.

In Chapters that followed, I presented evidence from our own empirical studies that demostrated children and adults' understanding of polite speech as reflecting a tradeoff between informational and social goals. 
Chapter 2 examined 2- to 4-year-old children's understanding of social goals behind language use, through the case study of polite requests with simple politeness markers such as "please," and "can you~". By 3 years, children were able to judge that speakers making polite requests were being more polite, and by 4 years children were able to reason that those speakers were also likely to be better play partners and to gain compliance to their requests. 

Chapter 3 examined older children's and adults' understanding of the tradeoff between social goals and informational goals, using the case study of white lies (versus blunt truths). By 6 years, children seem capable of using context information to reason about speaker goals and make judgments about whether the speaker was being nice or mean, and evaluate liars more positively given potential face threat to the listener than given no apparent face threat. 
We saw a developmental trend, where older children, like adults, rated polite liars more positively whereas younger participants tended to be divided. 
This age difference may be due to a discrepancy in goal priorities: Younger children may prioritize truth-telling, which can be a simple rule to follow (e.g., "Don't lie, always tell the truth") but as they get older, they might learn to consider other people's feelings and address the informational-social tradeoff more.

Finally, Chapter 4 examined adults' understanding of polite language in more detail, by looking at utterance prediction in a situation of potential face threat (e.g., speakers being asked to give feedback and answer "How was my poem?"), 
and proposed a model to formalize the notions of speaker goals as utilities that the speaker wants to maximize. 
We showed that our model predictions captured important key patterns of human judgments,
and that the model fit was superior to its variants with a subset of the three utilities of our model. 
Overall, the empirical work suggest that the goal-tradeoff framework both explains children's and adults' understanding of polite language well, and is useful for formalization and thus for making precise predictions of polite speech. 

What can we learn about the development of language understanding from this dissertation work?
Children start to show sensitivity to social goals behind language use from early on and are able to use that notion to judge polite versus impolite utterances accordingly by 3 years; 
by 6 years we see children being able to reason about the tradeoff between informational and social goals depending on the context,
finally, adults reason about polite utterances as reflecting a tradeoff between informational and social goals, that pertain to both saving the listener’s face but also being self-presentational, and that these notions can be represented by a formal model.

Naturally, this work could imply that language understanding evolves this way, such that
children first think about informational and social goals as largely separate rules that people need to follow, like “always tell the truth” or “say please when you make a request.” 
Then as they get older, children might start to think these two goals more integratively, as they get exposed to more situations where there is a clear tradeoff between the two. 
Finally, as they get even older, adults may start to pay attention to subtly different social concerns like saving the listener’s face versus presenting oneself as a good person, and address them differently.

But the current studies actually have not ruled out the possibility that young children in fact have some idea of the full tradeoff of all three goals. 
@asaba2018 has shown that 3- to 5-year-old children care about presenting their own competence to another person, and forgo opportunities to teach them new knowledge to take actions to show that they are competent.
Given that children act with self-presentational goals, it is plausible to think that children might use the notion of presentational goals to interpret other people’s utterances. 

The goal tradeoff framework thus provides us with a set of possible hypotheses that we can test about development of polite language understanding, and examine whether children start from the point of low competence to eventually get to high, adult-like competence, or children actually have adult-like competence to start with but perhaps with some performance obstacles that might conceal their capabilities.

In terms of what goals speakers might consider, 
this dissertation presented a framework that argues for a set of three different communicative goals that people might think about,
but it does not intend to argue that the list of goals is exhaustive; 
in fact, there could be many other utilities not explored here that people consider in language production. 
For example, the speaker might have a goal to try to achieve some immediate rewarding outcome in the world that surpasses informational or social goals. In another work, we have looked at some of these tradeoffs not in language understanding but in an active learning context, where people’s actions reflect tradeoffs between informational goals versus presentational goals versus immediate action goals, where people’s desire to look competent or get something to immediately work (like a machine to light up) could override their desire to gain new information [@yoon2018balancing]. The goal tradeoff framework can be a basis for exploring other goals that people might consider in different contexts.

What other factors might affect speakers’ goals for polite language production? 
In the current work, we considered how goal priorities might be shifted based on situational context (e.g., whether the listner baked or did not bake the cookies that are being asked about), but there are many other important factors that can contribute to the goal tradeoff decisions.
For example, people can shift their goal priorities based on who the listener is, where people might care more about informational goal when speaking to their close friend but they might care more about social face-saving when talking to a person who is older or has more authority than them. 
Indeed, @yoon2018balancing showed that adults predict an agent will make different decisions depending on whether their boss is present when they are about to choose an action to perform. 

Another important factor that has not been addressed is cultural, regional and linguistic variations. 
While we examined adults and children from the US only, these goal tradeoff decisions can interact differently depending on the speaker’s cultural norms, since other cultures might have different expectations for what goals are appropriate in a given situation. 
Indeed, preliminary work extending on Part 2 has shown some evidence that compared to US and Korean adults and older children who tend to say a polite liar is nice, Indian adults and children tend to say more often that the polite liar is *not* nice, which may be evidence that different cultures have different goal priorities depending on  context. 
It will be useful to think about how these variations across cultures and their interactions with different contexts and speaker and listener relationships might play a role in speaker decisions based on the goal tradeoff framework. 

Overall, this dissertation arguing for the framework of looking at polite language as reflecting goal tradeoffs helps further our understanding of how children and adults comprehend polite language, and how it can vary across contexts and cultures.
And politeness is just one way that language deviates from purely informational concern, as people try to boast, comfort, flirt, insult, and speak in many other ways that reflect our goals to affect others’ feelings or present particular views of ourselves. 
Thus, this framework will help advance our understanding of language comprehension and social cognition more broadly. 




---FIXME below---

There are limitations to the current theoretical framework and empirical evidence presented in here, that have important implications for future work. 
First, for the developmental work, Chapters 2 and 3 looked at distinct age groups, 2- to 4-year-olds and 5- to 8-year-olds respectively, making it difficult to tell how the polite speech understanding, especially regarding the tradeoff between informational and social goal, might develop across the entire relevant age span. 
For example, do 2- to 4-year-olds show even more of preference for prioritizing informational goals over social goals? Or do they not yet have the notion of goal tradeoff at all?
There were practical concerns that prevented younger children's participation in the study reported in Chapter 3, namely that it would be too difficult for younger children to understand the stories presented in that study (due to memory demand, tracking of second-order beliefs, etc.). 
It will be useful to conduct a follow-up task that is more accessible for younger children and can test their understanding of goal tradeoffs.
It will also be helpful to consider how children's utterance choices and evaluations may be formalized, which will help hone explanation for the development of polite language understanding and make precise predictions.

Second, the scope of contexts of polite speech use we explored thus far is limited. We have not examined other factors that may be integral to polite speech production and understanding, such as speaker-listener status differences (e.g., conversations between a teacher and student, instead of between friends), listener needs (e.g., listener is looking for feedback to enter a competition), and available utterances (e.g., other kinds of indirect speech such as "I don't think this cookie is very tasty").
Thus, it is an open question whether and how children and adults process these other kinds of relevant information and integrate them into their understanding of polite utterances. 

Also, here we addressed broadly three differentiable goals -- informational, prosocial, and self-presentational -- that speakers may consider, but in real life, there may be other goals that are important, or these goals may also be broken down further. 
For example, in the current work we supposed that speakers consider self-presentational goals to appear informative or to appear kind, but depending on the context, speakers may care about appearing competent and knowledgeable.
Indeed, people do account for this kind of presentational goal to determine their action in a social active learning context, where they must choose between maximal information gain (e.g., learn which button makes a machine work) versus presentation of oneself as competent [e.g., that they can make the machine work for sure; @yoon2018balancing].
Thus, future work should investigate how different desires than ones examined here may play roles in speakers' utterance choices.

Finally, the empirical studies presented here recruited participants in the US only, but there may be great variations in polite speech understanding depending on cultural norms and expectations. 
For example, some cultures and languages may emphasize prosocial goals more than informational goals and thus have expectations for speakers to prioritize kindness over informativity, whereas other cultures might value truthfulness as a greater virtue than face-saving.
Indeed, we have some preliminary evidence that Indian speakers, both adults and children, value informational goals more and are more charitable toward blunt truth-tellers than polite liars compared to US and Korean speakers. 
Formalisation and empirical test of these cultural variations will help further the understanding of polite language.

In sum, I argued for a goal-based framework for polite language understanding, in which speakers consider tradeoffs between informational and social concerns. 
Our empirical research shows that adults and children are sensitive to not only informational goals but also social goals behind language use, and consider tradeoffs between these goals when reasoning about speakers' utterance choices.
I also presented a formal model of the goal tradeoffs, which allowed for precise quantitative predictions that matched human adults' polite speech predictions well.
This theoretical approach accompanied by computational framework then can be a powerful tool in addressing possible future work to extend on many other factors that must be considered to explain human understanding of polite language, and pragmatics and social behaviors in general.







<!--chapter:end:06-conclusion.Rmd-->

`r if(knitr:::is_latex_output()) '\\appendix'`

`r if(!knitr:::is_latex_output()) '# (APPENDIX) Appendix {-}'` 

<!--
If you feel it necessary to include an appendix, it goes here.
-->

```{r, include=FALSE}
knitr::opts_chunk$set(echo = F, cache = T, warning=F, message=F, 
                      fig.width=4, fig.asp = 0.618, out.width = "75%", 
                      fig.align = 'center', fig.pos = 't')
```


# Supplementary materials for Chapter 3

## Stimuli

### Training trial

Nicole gave her friend a gift. Was Nicole nice? Was Nicole mean?

James hit his friend.
Was James nice? Was James mean?

Kyle broke his mom’s vase, and he told his mom the truth that he broke it. Was Kyle telling the truth?

Pam ate five cookies, but Pam told her mom a lie that she didn’t eat any cookie. Was Pam telling the truth?

### Example test story (experimental condition)

Look, this is Edward!
One day, Edward decided to bake some cookies.
Edward brought his cookie to school and met his friend Sally. Edward said to his friend Sally, “Here, try my cookie!”
Sally tasted the cookie,
and she did not like the cookie at all — she thought the cookie tasted yucky!
So did Sally like the cookie or did she not like the cookie?

Edward asked Sally, “Sally, how did you like my cookie?” Sally told Edward, “Edward, your cookie was tasty.”
So what did Sally tell Edward again?

Let’s think about the story again.
Sally thought the cookie was yucky.
And Sally told Edward that the cookie was yucky.
Was Sally nice? Was Sally mean? Was Sally telling the truth?

Look, this is Edward again!
One day, Edward decided to bake some cookies.
Edward brought his cookie to school and met his friend Mary. Edward said to his friend Mary, “Here, try my cookie!”
Mary tasted the cookie,
and she did not like the cookie at all — she thought the cookie tasted yucky!
So did Mary like the cookie or did she not like the cookie?

Edward asked Mary, “Mary, how did you like my cookie?” Mary told Edward, “Edward, your cookie was tasty.”
So what did Mary tell Edward again?

Let’s think about the story again.
Mary thought the cookie was yucky.
And Mary told Edward that the cookie was tasty.
Was Mary nice? Was Mary mean? Was Mary telling the truth?

Remember Sally and Mary from our story? Look, here they are.
Remember, Sally thought the cookie was yucky and told Edward that the cookie was yucky. 
Mary thought the cookie was yucky and told Edward that the cookie was tasty.
Who do you want to play with more, Sally or Mary? Why?

### Example test story (control condition)

Look, this is Sally!
One day, Sally saw a free cookie.
Sally said, “It’s a free cookie, I’ll try it!”
Sally tasted the cookie,
and she did not like the cookie at all — she thought the cookie tasted yucky!
So did Sally like the cookie or did she not like the cookie?

Sally’s friend Edward also wanted to taste the cookie. Edward asked Mary, “Sally, how did you like the cookie?” 
Sally told Edward, “Edward, the cookie was yucky.”
So what did Sally tell Edward again?

Let’s think about the story again.
Sally thought the cookie was yucky.
And Sally told Edward that the cookie was yucky
Was Sally nice? Was Sally mean? Was Sally telling the truth?

Look, this is Mary!
One day, Mary saw a free cookie.
Mary said, “It’s a free cookie, I’ll try it!”
Mary tasted the cookie,
and she did not like the cookie at all — she thought the cookie tasted yucky!
So did Mary like the cookie or did she not like the cookie?

Mary’s friend Edward also wanted to taste the cookie. Edward asked Mary, “Mary, how did you like the cookie?” 
Mary told Edward, “Edward, the cookie was tasty.”
So what did Mary tell Edward again?

Let’s think about the story again.
Mary thought the cookie was yucky.
And Mary told Edward that the cookie was tasty.
Was Mary nice? Was Mary mean? Was Mary telling the truth?

Remember Sally and Mary from our story? Look, here they are.
Remember, Sally thought the cookie was yucky and told Edward that the cookie was yucky. 
Mary thought the cookie was yucky and told Edward that the cookie was tasty.
Who do you want to play with more, Sally or Mary? Why?

## Supplemental figure

```{r}
trupol_appendix <- d_plot %>%
  ggplot(., aes(x=age, y=answer, col=cond)) +
  geom_jitter(height=.05, width=.05) +
  geom_smooth(span=2) +
  facet_grid(qkind~speaker) + 
  theme_few() +
  theme(legend.position = "bottom", legend.title = element_blank()) +
  geom_hline(aes(yintercept=0.5), linetype="dashed") +
  scale_colour_ptol() + 
  # scale_alpha_manual(values=c(0,1)) +
  # ggtitle("Expt 1: Judgments for honest vs. polite speaker") +
  ylab("Proportion \"yes [the speaker was _____]\"") +
  xlab("Age") +
  ylim(-0.1,1.1) +
  scale_y_continuous(breaks=seq(0,1,.5)) +
  guides(size=FALSE)

ggsave(trupol_appendix, file=here::here(child_lies_image_path, "trupol_plot_appendix.png"), width=5, height=5)
```

```{r figTrupolAppendix, fig.env = "figure*", fig.pos = "p", fig.width=7, fig.height=5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Speaker judgments by participants of different age (x-axis) for the honest speaker (left column) and the dishonest speaker (right), in different contexts (colors). Rows represent question types (e.g., Was Sally telling the truth?), and y-axis represents proportion saying \`\`yes\" to the question. Each point represents a participant response in a trial.", fig.scap="Speaker ratings for the experiment in Chapter 4 with age as a continuous variable."}
png::readPNG(here::here(child_lies_image_path, "trupol_plot_appendix.png")) %>%
  grid::grid.raster()
```


# Supplementary materials for Chapter 4

## Model details

The *literal listener* $L_0$ is a simple Bayesian agent that takes the utterance to be true:

$$P_{L_0}(s | w) \propto [\![ w ]\!] (s) * P(s).$$

\noindent where $[\![ w ]\!](s)$ is the truth-functional denotation of the utterance
$w$ (i.e. the utterance's literal meaning): It is a function
that maps world-states $s$ to Boolean truth values. The literal
meaning is used to update the literal listener's prior beliefs
over world states $P(s)$.

The *speaker* $S_1$ chooses utterances approximately optimally given a utility function, which can be decomposed into two components. 
First, informational utility ($U_{inf}$) is the amount of information a literal listener $L_0$ would still not know about world state $s$ after hearing a speaker's utterance $w$. 
Second, social utility ($U_{soc}$) is the expected subjective utility of the state inferred given the utterance $w$. 
The utility of an utterance subtracts the cost $c(w)$ from the weighted combination of the social and epistemic utilities. 

$$U(w; s; \phi_{S_1}) = \phi_{S_1} \cdot \ln(P_{L_0}(s \mid w)) + (1 - \phi_{S_1}) \cdot \mathbb{E}_{P_{L_0}(s \mid w)}[V(s)] - C(w).$$

\noindent The speaker then chooses utterances $w$ softmax-optimally given the state $s$ and his goal weight mixture $\phi_{S_1}$: 

$$P_{S_1}(w \mid s, \phi_{S_1}) \propto \mathrm{exp}(\lambda_{1} \cdot \mathbb{E}[U(w; s; \phi_{S_1})]).$$

## Literal semantic task

We probed judgments of literal meanings of the target words assumed by our model and used in our main experiment. 

### Participants 

51 participants with IP addresses in the United States were recruited on Amazon’s Mechanical Turk. 

### Design and Methods

We used thirteen different context items in which a speaker evaluated a performance of some kind. 
For example, in one of the contexts, Ann saw a presentation, and Ann’s feelings toward the presentation (true state) were shown on a scale from zero to three hearts (e.g., two out of three hearts filled in red color; see Figure\ \ref{fig:screenshot} for an example of the heart scale). 
The question of interest was "Do you think Ann thought the presentation was / wasn’t X?" and participants responded by choosing either “no” or “yes.” 
The target could be one of four possible words: *terrible*, *bad*, *good*, and *amazing*, giving rise to eight different possible utterances (with negation or no negation). 
Each participant read 32 scenarios, depicting every possible combination of states and utterances. 
The order of context items was randomized, and there were a maximum of four repeats of each context item per participant. 

### Behavioral results

We analyzed the data by collapsing across context items.
For each utterance-state pair, we computed the posterior distribution over the semantic weight (i.e., how consistent X utterance is with Y state) assuming a uniform prior over the weight (i.e., a standard Beta-Binomial model). 
Meanings of the words as judged by participants were as one would expect (Figure\ \ref{fig:litsem}). 

```{r litSem, echo=FALSE}
d <- read.csv(here::here(file_path, "literal_semantics.csv")) %>%
  mutate(utterance = fct_relevel(utterance, "terrible", "bad", "good", "amazing"))

ms <- d %>%
  mutate(positivity = fct_recode(positivity,
                                "it was ~ " = "it was ___",
                                "it wasn't ~ " = "it wasn't ___"
                                ),
         positivity = fct_relevel(positivity, "it was ~ ")) %>%
  group_by(positivity, state, utterance, subid) %>%
  summarize(
            judgment = mean(judgment, na.rm=TRUE)
          ) %>%
  group_by(positivity, state, utterance) %>%
  multi_boot_standard(col = "judgment") %>%
  mutate(judgment = mean)

litsem_plot <- qplot(state, judgment, 
      colour = positivity,
      data=ms) + 
  geom_line(aes(group=positivity)) +
  facet_grid(.~utterance) +
  xlab("state (0=worst)") +
  ylab("proportion of\n acceptances") +
  geom_errorbar(aes(ymin=ci_lower,ymax=ci_upper,width=.1)) +
  theme_few(base_size = 16) +
  scale_color_ptol(name="")+
  # scale_color_solarized() +
  theme(legend.position = "bottom") +
  geom_hline(yintercept = .5, lty=2)

ggsave(litsem_plot, file = "literal_semantics.png", width = 7, height = 3,
       path = here::here(file_path))
```

```{r litsemPlotPlacement, echo=FALSE, fig.width = 10, fig.height = 4, out.width = "\\textwidth", fig.pos = "!h", fig.cap = "Semantic measurement results. Proportion of acceptances of utterance types (shown in different colors) combined with target words (shown in different facets) given the true state represented on a scale of hearts. Error bars represent 95\\% confidence intervals.", fig.scap="Semantic measurement results for Chapter 4."}
png::readPNG(here::here(file_path, "literal_semantics.png")) %>%
  grid::grid.raster()
```

## Data analysis

We used `r cite_r(here::here(file_path, "politeness.bib"))` for all our analyses.

## Full statistics on human data

```{r brmTab, results='asis'}
apa_table(brm.tab, caption= "Predictor mean estimates with standard deviation and 95% credible interval information for a Bayesian linear mixed-effects model predicting negation production based on true state and speaker goal (with both-goal as the reference level).")

# brm.tab %>%
#   kable("latex", booktabs = T, escape=F,
#         caption = "Predictor mean estimates with standard deviation and 95\% credible interval information for a Bayesian linear mixed-effects model predicting negation production based on true state and speaker goal (with both-goal as the reference level).",
#         caption.short = "Predictor mean estimates with standard deviation and 95\% credible interval information for a Bayesian linear mixed-effects model predicting negation production ") %>%
#   row_spec(row = 0, bold = TRUE)
  # column_spec(column = 1, width = "4cm")
```

We used Bayesian linear mixed-effects models [`brms` package in R; @R-brms] using crossed random effects of true state and goal with maximal random effects structure [@gelman2006data; @barr2013random]. The full statistics are shown in Table \@ref(tab:brmTab).


## Model fitting and inferred parameters

```{r otherParams, results='asis'}
other_tab <- d_other_s %>%
  mutate(model = fct_relevel(model, "inf", "soc", "pres", "inf_pres", "inf_soc", "soc_pres", "full")) %>%
    mutate(model = case_when(
    model == "inf" ~ "informational only", 
    model == "soc" ~ "social only", 
    model == "pres" ~ "presentational only", 
    model == "inf_pres" ~ "informational, presentational", 
    model == "inf_soc" ~ "informational, social", 
    model == "soc_pres" ~ "social, presentational", 
    model == "full" ~ "informational, social, presentational" 
  )) %>%
  mutate(param = round(param, digits=2)) %>%
  spread(parameter, param)

colnames(other_tab) <- c("Model", "Cost of negation", "Speaker optimality")

# apa_table(other_tab, escape=FALSE, caption = "Inferred negation cost and speaker optimality parameters for all model variants.")

other_tab %>% 
  kable("latex", booktabs = T, escape=F,
        caption = "Inferred negation cost and speaker optimality parameters for all model variants.",
        caption.short = "Other inferred parameters for all model variants.") %>% 
  row_spec(row = 0, bold = TRUE)
```

Other than speaker goal mixture weights explained in the main text (shown in Table \@ref(tab:phi)), the full model has two global parameters: the speaker's soft-max parameter $\lambda_{S_2}$ and soft-max paramater of the hypothetical speaker that the pragmatic listener reasons about $\lambda_{S_1}$.
$\lambda_{S_1}$ was 1, and $\lambda_{S_2}$ was inferred from the data: 
We put a prior that was consistent with those used for similar models in this model class: $\lambda_{S_2}$ ~ $Uniform(0,20)$.
Finally, we incorporate the literal semantics data into the RSA model by maintaining uncertainty about the semantic weight of utterance $w$ for state $s$, for each of the states and utterances, and assuming a Beta-Binomial linking function between these weights and the literal semantics data (see *Literal semantics task* above).
We infer the posterior distribution over all of the model parameters and generate model predictions based on this posterior distribution using Bayesian data analysis [@lee2014]. 
We ran 4 MCMC chains for 80,000 iterations, discarding the first 40,000 for burnin. 
The inferred values of parameters are shown in Table \@ref(tab:otherParams).

## Data Availability

Our model, preregistration of hypotheses, procedure, data, and analyses are available at \url{https://github.com/ejyoon/polite_speaker}. 

## Supplemental Figures

```{r utterance, echo=FALSE}
plot.utt <- ggplot(data=ms_utt %>%
                     filter(source == "data" | model == "full") %>%
  mutate(positivity = fct_recode(positivity, 
                               "It was ~" = "yes",
                               "It wasn't ~" = "not",
                               "It was ~" = "It was~",
                               "It wasn't ~" = "It wasn't~"
                               ),
         positivity = fct_relevel(positivity, "It was ~")) %>%
                     mutate(
                       # positivity = fct_relevel(positivity, "not"),
                            true_state = fct_recode(true_state,
                                                    "0 heart" = "0", 
                                                    "1 heart" = "1", 
                                                    "2 hearts" = "2", 
                                                    "3 hearts" = "3" 
                                                    ),
                            goal = fct_recode(goal, "kind" = "social")), 
       aes(x=utterance, y=prob, group = interaction(positivity, source), colour = positivity, linetype = source)) +
  geom_line()+
  facet_grid(goal~true_state, labeller = labeller(goal = label_both)) +
  xlab("utterance") +
  ylab("proportion chosen") +
  geom_linerange(aes(ymin=ci_lower,ymax=ci_upper), position="dodge") +
  geom_hline(yintercept=.1, lty=2) +
  ylim(0,1)+
  scale_color_ptol()+
  # scale_color_solarized(labels = c("It wasn't~","It was~"))+
  ggthemes::theme_few()+
  theme(axis.text.x = element_text(angle = 45, vjust=0.5),
        legend.position = "bottom") +
  guides(colour=guide_legend(title="utterance type")) +
  scale_linetype_discrete(labels = c("data", "model"))

ggsave("speaker_production_utt_wMod.png", plot = plot.utt, width = 7, height = 5,
       path = here::here(file_path))
```

```{r utterancePlacement, echo=FALSE, out.width = "\\textwidth", fig.pos = "!h", fig.height=6, fig.cap="Experimental results (solid lines) and fitted predictions from the full model (dashed lines) for speaker production. Proportion of utterances chosen (utterance type – direct vs. indirect – in different colors and words shown on x-axis) given the true states (columns) and speaker goals (rows). Error bars represent 95\\% confidence intervals for the data and 95\\% highest density intervals for the model. Black dotted line represents the chance level.", fig.scap="Full comparison between model predictions and experimental results from Chapter 4."}
png::readPNG(here::here(file_path, "speaker_production_utt_wMod.png")) %>%
  grid::grid.raster()
```

```{r comparisonAllPlot, echo=FALSE}
plot.comp.all <- ms_utt %>%  
  mutate(model = case_when(
    model == "NA" ~ "Human data", 
    model == "inf" ~ "model: \ninformational \nonly", 
    model == "soc" ~ "model: \nsocial only", 
    model == "pres" ~ "model: \npresentational \nonly", 
    model == "inf_pres" ~ "model: \ninformational, \npresentational", 
    model == "inf_soc" ~ "model: \ninformational, \nsocial", 
    model == "soc_pres" ~ "model: \nsocial, \npresentational", 
    model == "full" ~ "model: \ninformational, \nsocial, \npresentational" 
  ),
  model = fct_relevel(model, "model: \ninformational \nonly", "model: \nsocial only", "model: \npresentational \nonly", "model: \nsocial, \npresentational", "model: \ninformational, \nsocial", "model: \ninformational, \npresentational", "model: \ninformational, \nsocial, \npresentational")) %>%
  mutate(positivity = fct_recode(positivity, 
                               "It was ~" = "yes",
                               "It wasn't ~" = "not",
                               "It was ~" = "It was~",
                               "It wasn't ~" = "It wasn't~"
                               ),
         positivity = fct_relevel(positivity, "It was ~")) %>%
  mutate(
    # positivity = fct_recode(positivity,
    #                              "It was ~" = "yes",
    #                              "It wasn't ~" = "not"),
         # positivity = fct_relevel(positivity, "It wasn't ~"),
         goal = fct_recode(goal, "kind" = "social") 
         ) %>%
  filter(true_state == "0") %>%
  ggplot(., 
       aes(x=utterance, y=prob, fill=positivity, 
           # group = interaction(positive, source), linetype = forcats::fct_rev(positive),
           group = positivity,
           colour = positivity)) +
  geom_hline(yintercept=.125, lty=2, color="gray") +
  geom_line()+
  facet_grid(goal~model, labeller = labeller(goal = label_both)) +
  xlab("utterance") +
  geom_linerange(aes(ymin=ci_lower,ymax=ci_upper), position="dodge") +
  ylim(0,.7)+
  scale_color_ptol(guide=FALSE)+
  # scale_color_solarized(guide=FALSE)+
  ggthemes::theme_few(base_size = 15)+
  ylab("proportion chosen") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        legend.position="bottom") +
  guides(color=guide_legend(title=NULL))

ggsave("model_comparisons_all.png", plot = plot.comp.all, width = 11, height = 6.5,
       path = here::here(file_path))

```

```{r comparisonAllPlacement, echo=FALSE, out.width = "\\textwidth", fig.pos = "!h", fig.width=11, fig.height=7, fig.cap="Comparison of predictions for proportion of utterances chosen by pragmatic speaker from possible model variants (left) and human data (rightmost) for average proportion of negation produced among all utterances, given true state of 0 heart and speaker with a goal to be informative (top), kind (middle), or both (bottom). Gray dotted line indicates chance level at 12.5\\%.", fig.scap="Full comparison of model variants for all conditions from the experiment in Chapter 4."}
png::readPNG(here::here(file_path, "model_comparisons_all.png")) %>%
  grid::grid.raster()
```


```{r negation, echo=FALSE}
plot.neg <- ms_neg %>%  
  mutate(model = case_when(
    model == "NA" ~ "Human data", 
    model == "inf" ~ "model: \ninformational \nonly", 
    model == "soc" ~ "model: \nsocial only", 
    model == "pres" ~ "model: \npresentational \nonly", 
    model == "inf_pres" ~ "model: \ninformational, \npresentational", 
    model == "inf_soc" ~ "model: \ninformational, \nsocial", 
    model == "soc_pres" ~ "model: \nsocial, \npresentational", 
    model == "full" ~ "model: \ninformational, \nsocial, \npresentational" 
  ),
  model = fct_relevel(model, "model: \ninformational \nonly", "model: \nsocial only", "model: \npresentational \nonly", "model: \nsocial, \npresentational", "model: \ninformational, \nsocial", "model: \ninformational, \npresentational", "model: \ninformational, \nsocial, \npresentational")) %>%
  ggplot(., 
       aes(x=true_state, y=prob, color = goal, group=goal)) +
  geom_line(stat="identity", position=position_dodge()) +
  xlab("true state") +
  ylab("proportion negation") +
  geom_linerange(aes(ymin=ci_lower,ymax=ci_upper), position=position_dodge(width=.05)) +
  theme_few(base_size = 15)+
  scale_color_solarized() +
  facet_grid(.~model) +
  theme(legend.position="bottom")

ggsave("speaker_production_neg_wMod.png", plot = plot.neg, width = 10, height = 5,
       path = here::here(file_path))
```

```{r negationPlacement, echo=FALSE, fig.width=11, fig.height=4, out.width = "\\textwidth", fig.pos = "!h", fig.cap="Experimental results (left) and fitted model predictions (right) for average proportion of negation produced among all utterances, given true states (x-axis) and goals (colors).", fig.scap="Comparison of expected proportion of negation from model predictions and experimental results from Chapter 4."}
png::readPNG(here::here(file_path, "speaker_production_neg_wMod.png")) %>%
  grid::grid.raster()
```

<!--chapter:end:07-appendix.Rmd-->

<!--
The bib chunk below must go last in this document according to how R Markdown renders.  More info is at http://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html
-->

<!-- 
If you'd like to change the name of the bibliography to something else,
delete "References" and replace it.
-->

# References {-}
<!--
This manually sets the header for this unnumbered chapter.
-->
\markboth{References}{References}
<!--
To remove the indentation of the first entry.
-->
\noindent

<!--
To create a hanging indent and spacing between entries.  These three lines may need to be removed for styles that don't require the hanging indent.
-->

\setlength{\parindent}{-0.20in}
\setlength{\leftskip}{0.20in}
\setlength{\parskip}{8pt}


<!--
This is just for testing with more citations for the bibliography at the end.  Add other entries into the list here if you'd like them to appear in the bibliography even if they weren't explicitly cited in the document.
-->

---
nocite: | 
  @angel2000, @angel2001, @angel2002a
...

<!--chapter:end:99-references.Rmd-->

