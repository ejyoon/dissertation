`r if(knitr:::is_latex_output()) '\\appendix'`

`r if(!knitr:::is_latex_output()) '# (APPENDIX) Appendix {-}'` 

<!--
If you feel it necessary to include an appendix, it goes here.
-->

```{r, include=FALSE}
knitr::opts_chunk$set(echo = F, cache = T, warning=F, message=F, 
                      fig.width=4, fig.asp = 0.618, out.width = "75%", 
                      fig.align = 'center', fig.pos = 't')
```

# Supplementary materials for Chapter 2

In this appendix, we present FIXME.

## Model details

The *literal listener* $L_0$ is a simple Bayesian agent that takes the utterance to be true:

$$P_{L_0}(s | w) \propto [\![ w ]\!] (s) * P(s).$$

\noindent where $[\![ w ]\!](s)$ is the truth-functional denotation of the utterance
$w$ (i.e. the utterance's literal meaning): It is a function
that maps world-states $s$ to Boolean truth values. The literal
meaning is used to update the literal listener's prior beliefs
over world states $P(s)$.

The *speaker* $S_1$ chooses utterances approximately optimally given a utility function, which can be decomposed into two components. 
First, informational utility ($U_{inf}$) is the amount of information a literal listener $L_0$ would still not know about world state $s$ after hearing a speaker's utterance $w$. 
Second, social utility ($U_{soc}$) is the expected subjective utility of the state inferred given the utterance $w$. 
The utility of an utterance subtracts the cost $c(w)$ from the weighted combination of the social and epistemic utilities. 

$$U(w; s; \phi_{S_1}) = \phi_{S_1} \cdot \ln(P_{L_0}(s \mid w)) + (1 - \phi_{S_1}) \cdot \mathbb{E}_{P_{L_0}(s \mid w)}[V(s)] - C(w).$$

\noindent The speaker then chooses utterances $w$ softmax-optimally given the state $s$ and his goal weight mixture $\phi_{S_1}$: 

$$P_{S_1}(w \mid s, \phi_{S_1}) \propto \mathrm{exp}(\lambda_{1} \cdot \mathbb{E}[U(w; s; \phi_{S_1})]).$$

## Literal semantic task

We probed judgments of literal meanings of the target words assumed by our model and used in our main experiment. 

### Participants 

51 participants with IP addresses in the United States were recruited on Amazon’s Mechanical Turk. 

### Design and Methods

We used thirteen different context items in which a speaker evaluated a performance of some kind. 
For example, in one of the contexts, Ann saw a presentation, and Ann’s feelings toward the presentation (true state) were shown on a scale from zero to three hearts (e.g., two out of three hearts filled in red color; see Figure\ \ref{fig:screenshot} for an example of the heart scale). 
The question of interest was "Do you think Ann thought the presentation was / wasn’t X?" and participants responded by choosing either “no” or “yes.” 
The target could be one of four possible words: *terrible*, *bad*, *good*, and *amazing*, giving rise to eight different possible utterances (with negation or no negation). 
Each participant read 32 scenarios, depicting every possible combination of states and utterances. 
The order of context items was randomized, and there were a maximum of four repeats of each context item per participant. 

### Behavioral results

We analyzed the data by collapsing across context items.
For each utterance-state pair, we computed the posterior distribution over the semantic weight (i.e., how consistent X utterance is with Y state) assuming a uniform prior over the weight (i.e., a standard Beta-Binomial model). 
Meanings of the words as judged by participants were as one would expect (Figure\ \ref{fig:litsem}). 

```{r litsem, echo=FALSE, fig.width = 10, fig.height = 4, out.width = "\\textwidth", fig.pos = "!h", fig.cap = "Semantic measurement results. Proportion of acceptances of utterance types (shown in different colors) combined with target words (shown in different facets) given the true state represented on a scale of hearts. Error bars represent 95\\% confidence intervals."}
d <- read.csv(here::here(file_path, "literal_semantics.csv")) %>%
  mutate(utterance = fct_relevel(utterance, "terrible", "bad", "good", "amazing"))

ms <- d %>%
  mutate(positivity = fct_recode(positivity,
                                "it was ~ " = "it was ___",
                                "it wasn't ~ " = "it wasn't ___"
                                ),
         positivity = fct_relevel(positivity, "it was ~ ")) %>%
  group_by(positivity, state, utterance, subid) %>%
  summarize(
            judgment = mean(judgment, na.rm=TRUE)
          ) %>%
  group_by(positivity, state, utterance) %>%
  multi_boot_standard(col = "judgment") %>%
  mutate(judgment = mean)

qplot(state, judgment, 
      colour = positivity,
      data=ms) + 
  geom_line(aes(group=positivity)) +
  facet_grid(.~utterance) +
  xlab("state (0=worst)") +
  ylab("proportion of\n acceptances") +
  geom_errorbar(aes(ymin=ci_lower,ymax=ci_upper,width=.1)) +
  theme_few(base_size = 16) +
  scale_color_ptol(name="")+
  # scale_color_solarized() +
  theme(legend.position = "bottom") +
  geom_hline(yintercept = .5, lty=2)

ggsave("literal_semantics.png", width = 7, height = 3,
       path = here::here(file_path))
```

## Data analysis

We used `r cite_r(here::here(file_path, "politeness.bib"))` for all our analyses.

## Full statistics on human data

```{r brmTab, results="asis"}
apa_table(brm.tab, caption= "Predictor mean estimates with standard deviation and 95% credible interval information for a Bayesian linear mixed-effects model predicting negation production based on true state and speaker goal (with both-goal as the reference level).")
```

We used Bayesian linear mixed-effects models [`brms` package in R; @R-brms] using crossed random effects of true state and goal with maximal random effects structure [@gelman2006data; @barr2013random]. The full statistics are shown in Table \@ref(tab:brmTab).

## Model fitting and inferred parameters

```{r otherParams, results='asis'}
other_tab <- d_other_s %>%
    mutate(model = case_when(
    model == "inf" ~ "ninformational only", 
    model == "soc" ~ "social only", 
    model == "pres" ~ "presentational only", 
    model == "inf_pres" ~ "ninformational, presentational", 
    model == "inf_soc" ~ "ninformational, social", 
    model == "soc_pres" ~ "social, presentational", 
    model == "full" ~ "ninformational, social, presentational" 
  )) %>%
  mutate(param = round(param, digits=2)) %>%
  spread(parameter, param)

colnames(other_tab) <- c("Model", "Cost of negation", "Speaker optimality")

apa_table(other_tab, escape=FALSE, caption = "Inferred negation cost and speaker optimality parameters for all model variants.")
```

Other than speaker goal mixture weights explained in the main text (shown in Table \@ref(tab:phi)), the full model has two global parameters: the speaker's soft-max parameter $\lambda_{S_2}$ and soft-max paramater of the hypothetical speaker that the pragmatic listener reasons about $\lambda_{S_1}$.
$\lambda_{S_1}$ was 1, and $\lambda_{S_2}$ was inferred from the data: 
We put a prior that was consistent with those used for similar models in this model class: $\lambda_{S_2}$ ~ $Uniform(0,20)$.
Finally, we incorporate the literal semantics data into the RSA model by maintaining uncertainty about the semantic weight of utterance $w$ for state $s$, for each of the states and utterances, and assuming a Beta-Binomial linking function between these weights and the literal semantics data (see *Literal semantics task* above).
We infer the posterior distribution over all of the model parameters and generate model predictions based on this posterior distribution using Bayesian data analysis [@lee2014]. 
We ran 4 MCMC chains for 80,000 iterations, discarding the first 40,000 for burnin. 
The inferred values of parameters are shown in Table \@ref(tab:otherParams).

## Data Availability

Our model, preregistration of hypotheses, procedure, data, and analyses are available at \url{https://github.com/ejyoon/polite_speaker}. 

## Supplemental Figures

```{r utterance, echo=FALSE, out.width = "\\textwidth", fig.pos = "!h", fig.height=6, fig.cap="Experimental results (solid lines) and fitted predictions from the full model (dashed lines) for speaker production. Proportion of utterances chosen (utterance type – direct vs. indirect – in different colors and words shown on x-axis) given the true states (columns) and speaker goals (rows). Error bars represent 95\\% confidence intervals for the data and 95\\% highest density intervals for the model. Black dotted line represents the chance level."}
plot.utt <- ggplot(data=ms_utt %>%
                     filter(source == "data" | model == "full") %>%
  mutate(positivity = fct_recode(positivity, 
                               "It was ~" = "yes",
                               "It wasn't ~" = "not",
                               "It was ~" = "It was~",
                               "It wasn't ~" = "It wasn't~"
                               ),
         positivity = fct_relevel(positivity, "It was ~")) %>%
                     mutate(
                       # positivity = fct_relevel(positivity, "not"),
                            true_state = fct_recode(true_state,
                                                    "0 heart" = "0", 
                                                    "1 heart" = "1", 
                                                    "2 hearts" = "2", 
                                                    "3 hearts" = "3" 
                                                    ),
                            goal = fct_recode(goal, "kind" = "social")), 
       aes(x=utterance, y=prob, group = interaction(positivity, source), colour = positivity, linetype = source)) +
  geom_line()+
  facet_grid(goal~true_state, labeller = labeller(goal = label_both)) +
  xlab("utterance") +
  ylab("proportion chosen") +
  geom_linerange(aes(ymin=ci_lower,ymax=ci_upper), position="dodge") +
  geom_hline(yintercept=.1, lty=2) +
  ylim(0,1)+
  scale_color_ptol()+
  # scale_color_solarized(labels = c("It wasn't~","It was~"))+
  ggthemes::theme_few()+
  theme(axis.text.x = element_text(angle = 45, vjust=0.5),
        legend.position = "bottom") +
  guides(colour=guide_legend(title="utterance type")) +
  scale_linetype_discrete(labels = c("data", "model"))

plot.utt

ggsave("speaker_production_utt_wMod.png", plot = plot.utt, width = 7, height = 5,
       path = here::here(file_path))
```

```{r comparisonAll, echo=FALSE, out.width = "\\textwidth", fig.pos = "!h", fig.width=11, fig.height=7, fig.cap="Comparison of predictions for proportion of utterances chosen by pragmatic speaker from possible model variants (left) and human data (rightmost) for average proportion of negation produced among all utterances, given true state of 0 heart and speaker with a goal to be informative (top), kind (middle), or both (bottom). Gray dotted line indicates chance level at 12.5\\%."}
plot.comp.all <- ms_utt %>%  
  mutate(model = case_when(
    model == "NA" ~ "Human data", 
    model == "inf" ~ "model: \ninformational \nonly", 
    model == "soc" ~ "model: \nsocial only", 
    model == "pres" ~ "model: \npresentational \nonly", 
    model == "inf_pres" ~ "model: \ninformational, \npresentational", 
    model == "inf_soc" ~ "model: \ninformational, \nsocial", 
    model == "soc_pres" ~ "model: \nsocial, \npresentational", 
    model == "full" ~ "model: \ninformational, \nsocial, \npresentational" 
  ),
  model = fct_relevel(model, "model: \ninformational \nonly", "model: \nsocial only", "model: \npresentational \nonly", "model: \nsocial, \npresentational", "model: \ninformational, \nsocial", "model: \ninformational, \npresentational", "model: \ninformational, \nsocial, \npresentational")) %>%
  mutate(positivity = fct_recode(positivity, 
                               "It was ~" = "yes",
                               "It wasn't ~" = "not",
                               "It was ~" = "It was~",
                               "It wasn't ~" = "It wasn't~"
                               ),
         positivity = fct_relevel(positivity, "It was ~")) %>%
  mutate(
    # positivity = fct_recode(positivity,
    #                              "It was ~" = "yes",
    #                              "It wasn't ~" = "not"),
         # positivity = fct_relevel(positivity, "It wasn't ~"),
         goal = fct_recode(goal, "kind" = "social") 
         ) %>%
  filter(true_state == "0") %>%
  ggplot(., 
       aes(x=utterance, y=prob, fill=positivity, 
           # group = interaction(positive, source), linetype = forcats::fct_rev(positive),
           group = positivity,
           colour = positivity)) +
  geom_hline(yintercept=.125, lty=2, color="gray") +
  geom_line()+
  facet_grid(goal~model, labeller = labeller(goal = label_both)) +
  xlab("utterance") +
  geom_linerange(aes(ymin=ci_lower,ymax=ci_upper), position="dodge") +
  ylim(0,.7)+
  scale_color_ptol(guide=FALSE)+
  # scale_color_solarized(guide=FALSE)+
  ggthemes::theme_few(base_size = 15)+
  ylab("proportion chosen") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
        legend.position="bottom") +
  guides(color=guide_legend(title=NULL))

plot.comp.all

ggsave("model_comparisons_all.png", plot = plot.comp.all, width = 11, height = 4,
       path = here::here(file_path))

```

```{r negation, echo=FALSE, fig.width=11, fig.height=4, out.width = "\\textwidth", fig.pos = "!h", fig.cap="Experimental results (left) and fitted model predictions (right) for average proportion of negation produced among all utterances, given true states (x-axis) and goals (colors)."}
plot.neg <- ms_neg %>%  
  mutate(model = case_when(
    model == "NA" ~ "Human data", 
    model == "inf" ~ "model: \ninformational \nonly", 
    model == "soc" ~ "model: \nsocial only", 
    model == "pres" ~ "model: \npresentational \nonly", 
    model == "inf_pres" ~ "model: \ninformational, \npresentational", 
    model == "inf_soc" ~ "model: \ninformational, \nsocial", 
    model == "soc_pres" ~ "model: \nsocial, \npresentational", 
    model == "full" ~ "model: \ninformational, \nsocial, \npresentational" 
  ),
  model = fct_relevel(model, "model: \ninformational \nonly", "model: \nsocial only", "model: \npresentational \nonly", "model: \nsocial, \npresentational", "model: \ninformational, \nsocial", "model: \ninformational, \npresentational", "model: \ninformational, \nsocial, \npresentational")) %>%
  ggplot(., 
       aes(x=true_state, y=prob, color = goal, group=goal)) +
  geom_line(stat="identity", position=position_dodge()) +
  xlab("true state") +
  ylab("proportion negation") +
  geom_linerange(aes(ymin=ci_lower,ymax=ci_upper), position=position_dodge(width=.05)) +
  theme_few(base_size = 15)+
  scale_color_solarized() +
  facet_grid(.~model) +
  theme(legend.position="bottom")

plot.neg

ggsave("speaker_production_neg_wMod.png", plot = plot.neg, width = 7, height = 3,
       path = here::here(file_path))
```


# Supplementary materials for Chapter 3

## Model output for Experiment 3.1

```{r trio-rt-model, results = 'asis'}
# ms_rt_trio %>% 
#   mutate(`95% HDI` = str_c("[", hdi_lower, ", ", hdi_upper, "]"),
#          condition = ifelse(condition == "asl", "ASL", str_to_title(condition))) %>% 
#   select(-hdi_lower, -hdi_upper) %>% 
#   arrange(m_rt) %>% 
#   rename(`Center Stimulus Type` = condition,
#          `Mean RT` = m_rt) %>% 
#   apa_table(placement = 'h',
#   caption = "Output of the regression predicting reaction time (milliseconds) as a function of center stimulus type in Experiment 1.")
```

```{r trio-acc-model, results = 'asis'}
# ms_acc_trio %>% 
#   mutate(`95% HDI` = str_c("[", hdi_lower, ", ", hdi_upper, "]"),
#          condition = ifelse(condition == "asl", "ASL", str_to_title(condition))) %>% 
#   arrange(prop) %>% 
#   select(-hdi_lower, -hdi_upper) %>% 
#   rename(`Center Stimulus Type` = condition,
#          `Mean Accuracy` = prop) %>% 
#   apa_table(placement = 'h',
#   caption = "Output of the logistic regression predicting accuracy as a function of center stimulus type in Experiment 1.")
```

```{r trio-acc-contrasts, results = 'asis'}
# ms_contrasts_trio_acc %>% 
#   mutate(`95% HDI` = str_c("[", hdi_lower, ", ", hdi_upper, "]"),
#          contrast = case_when(
#            contrast == "asl_face" ~ "ASL vs. Face",
#            contrast == "asl_noasl" ~ "ASL vs. English",
#            contrast == "face_object_bullseye" ~ "Face vs. Object/Bullseye",
#            contrast == "bullseye_chance" ~ "Bullseye vs. Chance",
#            contrast == "object_chance" ~ "Object vs. Chance"
#          )) %>% 
#   select(-hdi_lower, -hdi_upper) %>% 
#   arrange(prop) %>% 
#   rename(`Contrast` = contrast,
#          `Mean Difference Accuracy` = prop) %>% 
#   apa_table(placement = 'h',
#   caption = "Output of the model estimating differences in Accuracy for specific contrasts of interest in Experiment 1.")
```

```{r trio-rt-contrasts, results = 'asis'}
# ms_contrasts_trio_rt %>% 
#   mutate(`95% HDI` = str_c("[", hdi_lower, ", ", hdi_upper, "]"),
#          contrast = case_when(
#            contrast == "asl_face" ~ "ASL vs. Face",
#            contrast == "asl_noasl" ~ "ASL vs. English",
#            contrast == "face_object_bullseye" ~ "Face vs. Object/Bullseye"
#          )) %>% 
#   select(-hdi_lower, -hdi_upper) %>% 
#   arrange(rt) %>% 
#   rename(`Contrast` = contrast,
#          `Mean Difference RT` = rt) %>% 
#   apa_table(placement = 'h',
#   caption = "Output of the model estimating differences in RT for specific contrasts of interest in Experiment 1.")
```

```{r trio-ewma-cuts, results = 'asis'}
# ms_cuts_trio %>% 
#   mutate(`95% HDI` = str_c("[", hdi_lower, ", ", hdi_upper, "]"),
#          condition = ifelse(condition == "asl", "ASL", str_to_title(condition))) %>% 
#   select(-hdi_lower, -hdi_upper) %>% 
#   arrange(MAP) %>% 
#   rename(`Center Stimulus Type` = condition,
#          `Mean EWMA Cut Point` = MAP) %>% 
#   apa_table(placement = 'h',
#   caption = "Output of the model estimating the point in the Reaction Time distribution when children's Exponentially Weighted Moving Average statistic crossed the pre-defined guessing threshold for the ASL and Face center stimulus types in Experiment 1.")
```

```{r trio-guess-cuts, results = 'asis'}
# ms_guess_trio %>% 
#   mutate_if(is.numeric, round, 2) %>% 
#   mutate(`95% HDI` = str_c("[", ci_lower, ", ", ci_upper, "]"),
#          condition = ifelse(condition == "asl", "ASL", str_to_title(condition))) %>% 
#   select(-ci_lower, -ci_upper) %>% 
#   arrange(MAP) %>% 
#   rename(`Center Stimulus Type` = condition,
#          `Mean Language-driven` = MAP) %>% 
#   apa_table(placement = 'h',
#   caption = "Output of the model estimating the mean proportion of shifts categorized as language-driven by the Exponentially Weighted Moving Average model for the ASL and Face center stimulus types in Experiment 1.")
```

```{r trio-hddm, results = 'asis'}
# ms.hddm_trio %>% 
#   ungroup() %>% 
#   mutate_if(is.numeric, round, 2) %>% 
#   mutate(`95% HDI` = str_c("[", HDI_lower, ", ", HDI_upper, "]")) %>% 
#   select(-HDI_lower, -HDI_upper) %>% 
#   arrange(Parameter, Mean) %>% 
#   mutate(Parameter = str_to_title(Parameter)) %>% 
#   rename(`Mean Param Estimate` = Mean,
#          `Center Stim Type` = condition) %>% 
#   apa_table(placement = 'h',
#   caption = "Summary of the Drift Diffusion Model output for the drift rate and boundary separation parameters for both all four center stimulus types in Experiment 1.")
```

## Model output for Experiment 3.2

```{r noise-acc-model, results = 'asis'}
# # ms_acc_noise %>% 
# #   ungroup() %>% 
# #   mutate_if(is.character, str_to_title) %>% 
# #   mutate(`95% HDI` = str_c("[", hdi_lower, ", ", hdi_upper, "]")) %>% 
# #   arrange(prop) %>% 
# #   select(-hdi_lower, -hdi_upper) %>% 
# #   rename(`Noise Condition` = noise_condition,
# #          `Mean Accuracy` = prop,
# #          `Age Group` = age_category) %>% 
# #   apa_table(placement = 'h',
# #   caption = "Output of the logistic regression predicting accuracy as a function of noise condition and age group in Experiment 2.")
# ```
# 
# ```{r noise-rt-model, results = 'asis'}
# ms_rt_noise %>% 
#   ungroup() %>% 
#   mutate_if(is.character, str_to_title) %>% 
#   mutate(`95% HDI` = str_c("[", hdi_lower, ", ", hdi_upper, "]")) %>% 
#   select(-hdi_lower, -hdi_upper) %>% 
#   arrange(m_rt) %>% 
#   rename(`Noise Condition` = noise_condition,
#          `Mean RT` = m_rt,
#          `Age Group` = age_category) %>% 
#   apa_table(placement = 'h',
#   caption = "Output of the regression estimating reaction times (milliseconds) as a function of noise condition and age group in Experiment 2.")
```

```{r noise-guess-cuts, results = 'asis'}
# ms_guess_noise %>% 
#   select(-model, -parameter) %>% 
#   mutate_if(is.numeric, round, 2) %>% 
#   mutate_if(is.character, str_to_title) %>% 
#   select(noise_condition, everything()) %>% 
#   mutate(`95% HDI` = str_c("[", hdi_lower, ", ", hdi_upper, "]")) %>% 
#   select(-hdi_lower, -hdi_upper) %>% 
#   arrange(MAP) %>% 
#   rename(`Noise Condition` = noise_condition,
#          `Mean Language-driven` = MAP,
#          `Age Group` = age_category) %>% 
#   apa_table(placement = 'h',
#   caption = "Output of the model estimating the mean proportion of shifts categorized as language-driven by the Exponentially Weighted Moving Average model for the each noise condition and age group in Experiment 2.")
```


```{r noise-hddm, results = 'asis'}
# hddm_table_age %>% 
#   ungroup() %>% 
#   mutate_if(is.numeric, round, 2) %>% 
#   mutate(`95% HDI` = str_c("[", HDI_lower, ", ", HDI_upper, "]")) %>% 
#   select(-HDI_lower, -HDI_upper) %>% 
#   arrange(param_name, MAP) %>% 
#   mutate(param_name = str_to_title(param_name),
#          age_code = str_to_title(age_code)) %>% 
#   rename(`Parameter` = param_name,
#          `Mean Parameter Estimate` = MAP,
#          `Age Group` = age_code) %>% 
#   apa_table(placement = 'h',
#   caption = "Summary of the Drift Diffusion Model output for the drift rate and boundary separation parameters for both processing contexts and age groups in Experiment 2.")
```


# Supplementary materials for Chapter 4

## Analytic model specifications and output

### Experiment 1

\captionsetup[table]{labelformat=empty}

\section*{Table A1. Length of inspection times on exposure trials in Experiment 1 as a function of gaze, interval, and number of referents}
\texttt{Log(Inspection time) $\sim$ (Gaze + Log(Interval) + Log(Referents))$^2$ + (1 | subject)}

```{r e1 inspect model table, results = 'asis'}
# some code to clean up tables for paper
e1.tab.inspect <- broom::tidy(m1_rt_expt1) %>% 
  filter(group == "fixed") %>% 
  select(term:statistic) %>% 
  rename(t.value = statistic) %>% 
  mutate(p.value = 2 * (1 - pnorm(abs(t.value)))) %>% 
  mutate_at(.vars = c("estimate", "std.error", "t.value"), 
            .funs = round, digits = 2) %>% 
  mutate(p.value = ifelse(round(p.value, 3) == 0, "$<$ .001", round(p.value, 3))) %>% 
  rowwise() %>% 
  mutate(sig = getstars(p.value))

e1.tab.inspect$term <- c("Intercept","Gaze Condition","Log(Interval)",
                         "Log(Referents)","Gaze Condition*Log(Interval)", 
                         "Gaze Condition*Log(Referent)", "Log(Interval)*Log(Referent)")

names(e1.tab.inspect)[6] <- c("")

print(xtable(e1.tab.inspect,
             align = c("l","l","r","r","r","r","l"),
             label = "tab:e1_rt"),
      include.rownames=FALSE, 
      hline.after=c(0,nrow(e1.tab.inspect)),
      sanitize.text.function=function(x){x},
      table.placement = "h",
      comment = F)
```

\newpage
\section*{Table A2. Accuracy on test trials in Experiment 1 with inspection times on exposure trials included as a predictor}
\texttt{Correct $\sim$ (Trial Type + Gaze + Log(Interval) + Log(Referents) + \\ Log(Inspection Time))$^2$ + offset(logit($^1/_{Referents}$)) + (TrialType | subject)}

```{r e1 inspect model acc table, results = 'asis'}
# some code to clean up tables for paper
e1.tab.inspect.acc <- broom::tidy(m1_2way_acc_expt1_inspect) %>% 
  filter(group == "fixed") %>% 
  select(term:p.value) %>% 
  rename(z.value = statistic) %>% 
  mutate_at(.vars = c("estimate", "std.error", "z.value"), 
            .funs = round, digits = 2) %>% 
  mutate(p.value = ifelse(round(p.value, 3) == 0, "$<$ .001", round(p.value, 3))) %>% 
  rowwise() %>% 
  mutate(sig = getstars(p.value))

e1.tab.inspect.acc$term <- c("Intercept", "Switch Trial", "Gaze Condition","Log(Interval)",
                             "Log(Referents)","Log(Inspection Time)","Switch Trial*Gaze Condition",
                             "Switch Trial*Log(Interval)", "Switch Trial*Log(Referent)",
                             "Switch Trial*Log(Inspection Time)", "Gaze Condition*Log(Interval)",
                             "Gaze Condition*Log(Referent)", "Gaze Condition*Log(Inspection Time)",
                             "Log(Interval)*Log(Referent)", "Log(Interval)*Log(Inspection Time)",
                             "Log(Referents)*Log(Inspection Time)")

names(e1.tab.inspect.acc)[6] <- c("")

print(xtable(e1.tab.inspect.acc,
             align = c("l","l","r","r","r","r","l"),
             label = "tab:e1_acc_it"),
      include.rownames=FALSE,hline.after=c(0,nrow(e1.tab.inspect.acc)),
      sanitize.text.function=function(x){x},
      table.placement = "h",
      comment = F)
```

\newpage

### Experiment 2

\section*{Table A3. Length of inspection times on exposure trials in Experiment 2 as a function of gaze and interval}
\texttt{Log(Inspection time) $\sim$ Gaze * Log(Interval) + (1 | subject)}

```{r e2 inspect model table, results = 'asis'}
# some code to clean up tables for paper
e2.tab.inspect <- broom::tidy(m1_rt_expt2) %>% 
  filter(group == "fixed") %>% 
  select(term:statistic) %>% 
  rename(t.value = statistic) %>% 
  mutate(p.value = 2 * (1 - pnorm(abs(t.value)))) %>% 
  mutate_at(.vars = c("estimate", "std.error", "t.value"), 
            .funs = round, digits = 2) %>% 
  mutate(p.value = ifelse(round(p.value, 3) == 0, "$<$ .001", round(p.value, 3))) %>% 
  rowwise() %>% 
  mutate(sig = getstars(p.value))

e2.tab.inspect$term <- c("Intercept", "Gaze Condition", "Log(Interval)",
                         "Gaze Condition*Log(Interval)")

names(e2.tab.inspect)[6] <- c("")

print(xtable(e2.tab.inspect,
             align = c("l","l","r","r","r","r","l"),
             label = "tab:e2_rt"),
      include.rownames=FALSE,hline.after=c(0,nrow(e2.tab.inspect)),
      sanitize.text.function=function(x){x},
      table.placement = "h",
      comment = F)
```

\section*{Table A4. Accuracy on test trials in Experiment 2 with inspection times on exposure trials included as a predictor}
\texttt{Correct $\sim$ (Trial Type + Gaze + Log(Interval) + Log(Inspection Time))$^2$ + \\ offset(logit($^1/_{Referents}$)) + (TrialType | subject)}

```{r e2 inspect model acc table, results = 'asis'}
# some code to clean up tables for paper
e2.tab.inspect.acc <- broom::tidy(m2_inspect_e2) %>% 
  filter(group == "fixed") %>% 
  select(term:p.value) %>% 
  rename(z.value = statistic) %>% 
  mutate_at(.vars = c("estimate", "std.error", "z.value"), 
            .funs = round, digits = 2) %>% 
  mutate(p.value = ifelse(round(p.value, 3) == 0, "$<$ .001", round(p.value, 3))) %>% 
  rowwise() %>% 
  mutate(sig = getstars(p.value))

e2.tab.inspect.acc$term <- c("Intercept", "Gaze Condition", "Switch Trial", "Log(Interval)",
                             "Log(Inspection Time)", "Switch Trial*Gaze Condition",
                             "Gaze Condition*Log(Interval)", "Gaze Condition*Log(Inspection Time)",
                             "Switch Trial*Log(Interval)", "Switch Trial*Log(Inspection Time)", 
                             "Log(Interval)*Log(Inspection Time)")

names(e2.tab.inspect.acc)[6] <- c("")

print(xtable(e2.tab.inspect.acc,
             align = c("l","l","r","r","r","r","l"),
             label = "tab:e2_acc_it"),
      include.rownames=FALSE,hline.after=c(0,nrow(e2.tab.inspect.acc)),
      sanitize.text.function=function(x){x},
      table.placement = "h",
      comment = F)
```

\newpage

### Experiment 3

\section*{Table A5. Accuracy on exposure trials in Experiment 3 as a function of reliability condition and participants' subjective reliability judgments}
\texttt{Correct-Exposure $\sim$ Reliability Condition * Subjective Reliability + \\  offset(logit($^1/_{Referents}$)) + (1 | subject)}

```{r e3 gf on exposure table, results = 'asis'}
# some code to clean up tables for paper
e3.tab.gf.exposure <- broom::tidy(m1_expo_expt3) %>% 
filter(group == "fixed") %>% 
select(term:p.value) %>% 
rename(z.value = statistic) %>% 
mutate_at(.vars = c("estimate", "std.error", "z.value"), 
.funs = round, digits = 2) %>% 
mutate(p.value = ifelse(round(p.value, 3) == 0, "$<$ .001", round(p.value, 3))) %>% 
rowwise() %>% 
mutate(sig = getstars(p.value))

e3.tab.gf.exposure$term <- c("Intercept", "Reliability Condition", "Subjective Reliability",
"Reliability Condition*Subjective Reliability")

names(e3.tab.gf.exposure)[6] <- c("")

print(xtable(e3.tab.gf.exposure,
align = c("l","l","r","r","r","r","l"),
label = "tab:e3_gf_exp"),
include.rownames=FALSE,hline.after=c(0,nrow(e3.tab.gf.exposure)),
sanitize.text.function=function(x){x},
table.placement = "h",
comment = F)
```

\section*{Table A6. Accuracy on test trials in Experiment 3 as a function of reliability condition}
\texttt{Correct $\sim$ Trial Type * Reliability Condition + offset(logit($^1/_{Referents}$)) + \\ (Trial Type | subject)}

```{r e3 acc test rel cond table, results = 'asis'}
# some code to clean up tables for paper
e3.tab.acc.rel.cond <- broom::tidy(m1_expt3) %>% 
filter(group == "fixed") %>% 
select(term:p.value) %>% 
rename(z.value = statistic) %>% 
mutate_at(.vars = c("estimate", "std.error", "z.value"), 
.funs = round, digits = 2) %>% 
mutate(p.value = ifelse(round(p.value, 3) == 0, "$<$ .001", round(p.value, 3))) %>% 
rowwise() %>% 
mutate(sig = getstars(p.value))

e3.tab.acc.rel.cond$term <- c("Intercept", "Trial Type", "Reliability Condition",
"Reliability Condition*Trial Type")

names(e3.tab.acc.rel.cond)[6] <- c("")

print(xtable(e3.tab.acc.rel.cond,
align = c("l","l","r","r","r","r","l"),
label = "tab:e3_acc_rel_cond"),
include.rownames=FALSE,hline.after=c(0,nrow(e3.tab.acc.rel.cond)),
sanitize.text.function=function(x){x},
table.placement = "h",
comment = F)
```

\newpage
\section*{Table A7. Accuracy on test trials in Experiment 3 as a function of reliability condition and participants' use of gaze on exposure trials}
\texttt{Correct $\sim$ (Trial Type + Reliability Condition + Correct-Exposure)$^2$ \\ + offset(logit($^1/_{Referents}$)) + (Trial Type | subject)}

```{r e3 acc test rel and gaze follow table, results = 'asis'}
# some code to clean up tables for paper
e3.tab.acc.rel.cond.gf <- broom::tidy(m2a_expt3) %>% 
  filter(group == "fixed") %>% 
  select(term:p.value) %>% 
  rename(z.value = statistic) %>% 
  mutate_at(.vars = c("estimate", "std.error", "z.value"), 
            .funs = round, digits = 2) %>% 
  mutate(p.value = ifelse(round(p.value, 3) == 0, "$<$ .001", round(p.value, 3))) %>% 
  rowwise() %>% 
  mutate(sig = getstars(p.value))

e3.tab.acc.rel.cond.gf$term <- c("Intercept", "Correct Exposure", "Trial Type", "Reliability Condition",
                                 "Correct Exposure*Trial Type", "Correct Exposure*Reliability",
                                 "Reliability Condition*Trial Type")

names(e3.tab.acc.rel.cond.gf)[6] <- c("")

print(xtable(e3.tab.acc.rel.cond.gf,
             align = c("l","l","r","r","r","r","l"),
             label = "tab:e3_acc_rel_cond_gf"),
      include.rownames=FALSE,hline.after=c(0,nrow(e3.tab.acc.rel.cond.gf)),
      sanitize.text.function=function(x){x},
      table.placement = "h",
      comment = F)
```

\section*{Table A8. Accuracy on test trials in Experiment 3 as a function of each participants' accuracy on exposure trials}
\texttt{Correct $\sim$ Trial Type * Total Correct Exposure + offset(logit($^1/_{Referents}$)) + \\ (Trial Type | subject)}

```{r e3 acc test gaze use table, results = 'asis'}
# some code to clean up tables for paper
e3.tab.acc.gaze.use <- broom::tidy(m2b_expt3) %>% 
  filter(group == "fixed") %>% 
  select(term:p.value) %>% 
  rename(z.value = statistic) %>% 
  mutate_at(.vars = c("estimate", "std.error", "z.value"), 
            .funs = round, digits = 2) %>% 
  mutate(p.value = ifelse(round(p.value, 3) == 0, "$<$ .001", round(p.value, 3))) %>% 
  rowwise() %>% 
  mutate(sig = getstars(p.value))

e3.tab.acc.gaze.use$term <- c("Intercept", "Total Exposure Correct", "Trial Type",
                              "Total Exposure Correct*Trial Type")

names(e3.tab.acc.gaze.use)[6] <- c("")

print(xtable(e3.tab.acc.gaze.use,
             align = c("l","l","r","r","r","r","l"),
             label = "tab:e3_acc_gaze_use"),
      include.rownames=FALSE,hline.after=c(0,nrow(e3.tab.acc.gaze.use)),
      sanitize.text.function=function(x){x},
      table.placement = "h",
      comment = F)
```

\newpage
\section*{Table A9. Accuracy on test trials in Experiment 3 as a function of each participants' subjective reliability judgment}
\texttt{Correct $\sim$ Trial Type * Subjective Reliability + offset(logit($^1/_{Referents}$)) + \\ (Trial Type | subject)}

```{r e3 acc test subj reliability, results = 'asis'}
# some code to clean up tables for paper
e3.tab.acc.subj.rel <- broom::tidy(m3_expt3) %>% 
  filter(group == "fixed") %>% 
  select(term:p.value) %>% 
  rename(z.value = statistic) %>% 
  mutate_at(.vars = c("estimate", "std.error", "z.value"), 
            .funs = round, digits = 2) %>% 
  mutate(p.value = ifelse(round(p.value, 3) == 0, "$<$ .001", round(p.value, 3))) %>% 
  rowwise() %>% 
  mutate(sig = getstars(p.value))

e3.tab.acc.subj.rel$term <- c("Intercept", "Subjective Reliability", "Trial Type",
                              "Subjective Reliability*Trial Type")

names(e3.tab.acc.subj.rel)[6] <- c("")

print(xtable(e3.tab.acc.subj.rel,
             align = c("l","l","r","r","r","r","l"),
             label = "tab:e3_acc_subj_rel"),
      include.rownames=FALSE,hline.after=c(0,nrow(e3.tab.acc.subj.rel)),
      sanitize.text.function=function(x){x},
      table.placement = "h",
      comment = F)
```

\section*{Table A10. Accuracy on test trials in Experiment 3 as a function of reliability condition and inspection time on exposure trials}
\texttt{Correct $\sim$ (Trial Type + Reliability condition + Trial Type + \\ Log(Inspection Time))$^2$ + offset(logit($^1/_{Referents}$)) + (Trial Type | subject)}

```{r e3 acc test inspection time table, results = 'asis'}
# some code to clean up tables for paper
e3.tab.acc.inspection <- broom::tidy(m4a_expt3_2) %>% 
  filter(group == "fixed") %>% 
  select(term:p.value) %>% 
  rename(z.value = statistic) %>% 
  mutate_at(.vars = c("estimate", "std.error", "z.value"), 
            .funs = round, digits = 2) %>% 
  mutate(p.value = ifelse(round(p.value, 3) == 0, "$<$ .001", round(p.value, 3))) %>% 
  rowwise() %>% 
  mutate(sig = getstars(p.value))

e3.tab.acc.inspection$term <- c("Intercept","Log(Inspection Time)", "Trial Type",
                                "Reliability Condition", "Log(Inspection Time)*Trial Type",
                                "Log(Inspection Time)*Reliability Condition", 
                                "Trial Type*Reliability Condition")

names(e3.tab.acc.inspection)[6] <- c("")

print(xtable(e3.tab.acc.inspection,
             align = c("l","l","r","r","r","r","l"),
             label = "tab:e3_acc_inspect"),
      include.rownames=FALSE,hline.after=c(0,nrow(e3.tab.acc.inspection)),
      sanitize.text.function=function(x){x},
      table.placement = "h",
      comment = F)
```

\newpage

### Experiment 4

\section*{Table A11. Accuracy on test trials in Experiment 4 as a function of gaze and interval}
\texttt{Correct $\sim$ (Trial Type + Gaze + Log(Interval))$^2$ + offset(logit($^1/_{Referents}$)) + \\ (Trial Type | subject)}

```{r e4 acc test inspection time table, results = 'asis'}
# some code to clean up tables for paper
e4.tab.acc <- broom::tidy(m1_acc_expt4) %>% 
  filter(group == "fixed") %>% 
  select(term:p.value) %>% 
  rename(z.value = statistic) %>% 
  mutate_at(.vars = c("estimate", "std.error", "z.value"), 
            .funs = round, digits = 2) %>% 
  mutate(p.value = ifelse(round(p.value, 3) == 0, "$<$ .001", round(p.value, 3))) %>% 
  rowwise() %>% 
  mutate(sig = getstars(p.value))

e4.tab.acc$term <- c("Intercept", "Trial Type", "Gaze Condition", "Log(Interval)",
                     "Trial Type*Gaze Condition", "Trial Type*Log(Interval)", 
                     "Gaze Condition*Log(Interval)")

names(e4.tab.acc)[6] <- c("")

print(xtable(e4.tab.acc,
             align = c("l","l","r","r","r","r","l"),
             label = "tab:e4_acc"),
      include.rownames=FALSE,hline.after=c(0,nrow(e3.tab.acc.inspection)),
      sanitize.text.function=function(x){x},
      table.placement = "h",
      comment = F)
```
